<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blog on chrislaing.net</title>
    <link>http://chrislaing.net/blog/</link>
    <description>Recent content in Blog on chrislaing.net</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-gb</language>
    <lastBuildDate>Tue, 16 Jul 2024 10:00:00 +1300</lastBuildDate><atom:link href="http://chrislaing.net/blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>On the Economics and Ergonomics of LLMs</title>
      <link>http://chrislaing.net/blog/the-economics-and-ergonomics-of-ai/</link>
      <pubDate>Tue, 16 Jul 2024 10:00:00 +1300</pubDate>
      
      <guid>http://chrislaing.net/blog/the-economics-and-ergonomics-of-ai/</guid>
      <description>&lt;p&gt;For all the millions of words that have been devoted to the capabilities of LLMs, the economics and ergonomiocs of these systems seems to me to be under-discussed. In much the same way that technology changes - from records to cds to streaming - have been a dominant factor in the evolution of popular music, prosaic matters such as cost structures will have a substantial influence on the development and impact of AI. While it is still early days for LLMs, there are already signs that economics factors are impacting everything from product design and technology choice to adoption and even regulation.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>The Decomposition of Large Language Models</title>
      <link>http://chrislaing.net/blog/decomposition-of-llms/</link>
      <pubDate>Tue, 30 May 2023 09:00:00 +1300</pubDate>
      
      <guid>http://chrislaing.net/blog/decomposition-of-llms/</guid>
      <description>&lt;p&gt;While many AI systems can be very complex, Large Language Models (LLMs) seem to be refreshingly simple to understand. With their ability to generate human-like text, applications like ChatGPT have captured the popular imagination. However, as compelling an experience as chatbots are, the tradeoffs that they make can lead us to misunderstand LLMs as a whole. In this post, we will explore the idea that the functions of LLMs can be thought of as discrete capabilities, and how different composition of these functions leads to a much wider variety of user experiences.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>The Large Language Model Iceberg</title>
      <link>http://chrislaing.net/blog/the-large-language-model-iceberg/</link>
      <pubDate>Sat, 01 Apr 2023 13:30:00 +1300</pubDate>
      
      <guid>http://chrislaing.net/blog/the-large-language-model-iceberg/</guid>
      <description>&lt;p&gt;As the capabilities of Artificial Intelligence (AI) continue to evolve, the term &amp;ldquo;chatbot&amp;rdquo; has become synonymous with a new era of digital interactions. What was once a seemingly futuristic concept is now an integral part of our everyday lives. However, it is the Machine Learning models underlying them - Large Language Models (LLMs) - that are the true powers in these waters.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Three Categories of AI</title>
      <link>http://chrislaing.net/blog/three-categories-of-ai/</link>
      <pubDate>Sun, 25 Jul 2021 19:00:00 +1300</pubDate>
      
      <guid>http://chrislaing.net/blog/three-categories-of-ai/</guid>
      <description>&lt;p&gt;The term &amp;ldquo;AI&amp;rdquo; has at least three entirely different meanings in the modern business context, and any particular business leader usually has only one of these meanings in mind when they use the term. Not only is it common for participants in a discussion to have different interpretations of the term &amp;ldquo;AI&amp;rdquo;, but most will be unaware that this terminological confusion exists, leaving leaders in both public and private sector organisations poorly equipped to discuss one of the most important technologies of our time.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>If it&#39;s not mysterious, it&#39;s not AI</title>
      <link>http://chrislaing.net/blog/its-not-ai/</link>
      <pubDate>Thu, 08 Jul 2021 17:30:00 +1300</pubDate>
      
      <guid>http://chrislaing.net/blog/its-not-ai/</guid>
      <description>&lt;p&gt;Businesses are deeply confused about what AI is, and they have every right to be. Differences in terminology have plagued the Data-AI-Software landscape for many years, as anyone who has ever looked for a job as a &amp;ldquo;Data Scientist&amp;rdquo; will attest. Attempts to demystify the topic either conjure a series of analogies that are then strained to breaking point, or try to delve into the actual technology behind the hype, leaving everyone more confused than they were before.&lt;/p&gt;
&lt;p&gt;I will attempt something different: removing the mystery by embracing the mystery.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>The Memo</title>
      <link>http://chrislaing.net/blog/the-memo/</link>
      <pubDate>Sun, 20 Jun 2021 14:00:00 +1300</pubDate>
      
      <guid>http://chrislaing.net/blog/the-memo/</guid>
      <description>&lt;p&gt;In 2002, Amazon&amp;rsquo;s Jeff Bezos issued a memo that has entered tech industry canon. The memo, known as the &amp;ldquo;API Mandate&amp;rdquo;, is generally perceived as being a statement about technology at Amazon, and is therefore widely admired by technologists and wholly ignored by executives. This is unfortunate, because it&amp;rsquo;s no exaggeration to say that the API Mandate completely transformed Amazon as a business and laid the foundation for its success. Better still, unlike many things that global technology titans do, it is something that can be replicated and put to use by almost any business.&lt;/p&gt;
&lt;p&gt;In this post, we&amp;rsquo;ll talk about the memo, and how it created the systems and incentives for radical organisational transformation.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>The Business Implications of Combinatorial Optimisation by Deep Learning</title>
      <link>http://chrislaing.net/blog/business-implications-of-combinatorial-optimisation/</link>
      <pubDate>Mon, 31 May 2021 19:30:00 +1300</pubDate>
      
      <guid>http://chrislaing.net/blog/business-implications-of-combinatorial-optimisation/</guid>
      <description>&lt;p&gt;Recently, Deep Learning has revolutionised a multitude of technical fields, most notably Computer Vision and Natural Language Processing. The implications for business are enormous, with the ramifications of these change still filtering through the mostly technology-shy world of business. There are signs that Combinatorial Optimisation might be the next technical field to undergo Revolution-By-Neural-Network. If this comes to fruition, then the impact on business will be seismic.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>The Bitter Lesson Conditions</title>
      <link>http://chrislaing.net/blog/the-bitter-lesson-conditions/</link>
      <pubDate>Thu, 27 May 2021 11:30:00 +1300</pubDate>
      
      <guid>http://chrislaing.net/blog/the-bitter-lesson-conditions/</guid>
      <description>The hard truth of AI is that methods that exploit deep, hard-won human knowledge about a particular domain are outperformed by methods that cleverly exploit the increasing power of computation.
I have a modest proposal to distill this fundamental truth into a set of conditions which, when met, will revolutionise a given field.
Lineage I do not claim this insight about the fundamental mechanism of progress in AI as original; I have been heavily influenced by Richard Sutton&amp;rsquo;s powerful essay The Bitter Lesson.</description>
    </item>
    
    <item>
      <title>Odds and Ends #4</title>
      <link>http://chrislaing.net/blog/odds-and-ends-4/</link>
      <pubDate>Wed, 22 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>http://chrislaing.net/blog/odds-and-ends-4/</guid>
      <description>I just discovered kops, apparently an excellent way to deploy and manage Kubernetes clusters on the cloud. Since managing a k8s cluster seems to be a full-time job at the best of times, I&amp;rsquo;m interested to see if this really does make it much easier. I have a very mild case of podcast addiction, and am always looking for something great to add to my collection of subscriptions. Nikita Voloboev has published a very interesting list of podcasts.</description>
    </item>
    
    <item>
      <title>Odds and Ends #3</title>
      <link>http://chrislaing.net/blog/odds-and-ends-3/</link>
      <pubDate>Sun, 02 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>http://chrislaing.net/blog/odds-and-ends-3/</guid>
      <description>My former colleagues at Blue Yonder (now part of JDA) have introduced Kartothek, software for managing tables stored as parquet files. A great set of documentation on going zero to JupyterHub with Kubernetes. A related piece from Jim Crist on installing JupyterHub on an existing Hadoop cluster. An interesting paper interoducing PATE from a couple of years ago that had passed me by. PATE stands for Private Aggregation of Teacher Ensembles, and is a method for doing semi-supervised transfer learning from private data.</description>
    </item>
    
    <item>
      <title>Odds and Ends #2</title>
      <link>http://chrislaing.net/blog/odds-and-ends-2/</link>
      <pubDate>Fri, 01 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>http://chrislaing.net/blog/odds-and-ends-2/</guid>
      <description>Naftali Tishby on the Information Theory of Deep Learning (embedded below). I&amp;rsquo;m very enthusiastic about this kind of work, and have resolved to find and read more of it. a16z&amp;rsquo;s AI Playbook may be a couple of years old now, but it&amp;rsquo;s still an important read. Traces is a Python library for unevenly-spaced time series analysis. I haven&amp;rsquo;t had a problem to really try this out on, but the website looks slick 👌🏻.</description>
    </item>
    
    <item>
      <title>Odds and Ends #1</title>
      <link>http://chrislaing.net/blog/odds-and-ends-1/</link>
      <pubDate>Sat, 23 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>http://chrislaing.net/blog/odds-and-ends-1/</guid>
      <description> Spektral is a framework for relational representation learning, built in Python and based on the Keras API. The field of Geometric Deep Learning is starting to get some traction. In particular, doing Deep Learning on graphs presents some interesting possibilities. RPC Frameworks: gRPC vs Thrift vs RPyC for python. The state of Python Packaging. Packing in Python is both improving dramatically and harder than it should be. </description>
    </item>
    
    <item>
      <title>Keybase: Keys for everyone! Part II</title>
      <link>http://chrislaing.net/blog/keybase-keys-for-everyone-part-ii/</link>
      <pubDate>Mon, 20 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>http://chrislaing.net/blog/keybase-keys-for-everyone-part-ii/</guid>
      <description>&lt;p&gt;In a &lt;a href=&#34;http://chrislaing.net/blog/keybase-keys-for-everyone-part-i/&#34;&gt;previous post&lt;/a&gt;, we discussed &lt;a href=&#34;https://keybase.io&#34;&gt;Keybase&lt;/a&gt;, a clever company that is solving a lot of the classic problems that users have had with PGP: managing keys, verifying identities, trusting third parties, and user experience.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Keybase: Keys for everyone! Part I</title>
      <link>http://chrislaing.net/blog/keybase-keys-for-everyone-part-i/</link>
      <pubDate>Sun, 13 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>http://chrislaing.net/blog/keybase-keys-for-everyone-part-i/</guid>
      <description>&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;http://chrislaing.net/img/2016/11/chrislaing_keybase_proof_graph.png&#34;
         alt=&#34;Graph of Keybase proofs for Keybase user chrislaing&#34;/&gt;
&lt;/figure&gt;

Encryption is a topic that has fascinated me for years, less because of its mathematical basis than its applications, both existing and potential. By far my favourite project in this realm is &lt;a href=&#34;https://keybase.io&#34;&gt;Keybase&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>A New Hope</title>
      <link>http://chrislaing.net/blog/a-new-hope/</link>
      <pubDate>Thu, 03 Nov 2016 23:04:26 +0100</pubDate>
      
      <guid>http://chrislaing.net/blog/a-new-hope/</guid>
      <description>&lt;p&gt;Many years ago, I had a blog. Being perfectly honest, it wasn&amp;rsquo;t a very good blog; it consisted mainly of rants of one kind or another, inane musings, and the occasional photo from my holidays. On the modern web, social media is the default depository for said rants, musings, and photos, and so I had no need of a dedicated space on my website to share them.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
